{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYWMIXDeILZi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up constants\n",
        "IMG_SIZE = (300, 300)  # EfficientNetB3 recommended size\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30  # Increased epochs for better learning\n",
        "\n",
        "# Define the path to the images folder\n",
        "data_dir = '/content/drive/My Drive/images'\n",
        "print(\"Contents of data_dir:\")\n",
        "print(os.listdir(data_dir))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update class names to include SCC\n",
        "class_names = ['MEL', 'NV', 'BCC', 'SCC']\n",
        "for class_name in class_names:\n",
        "    if not os.path.isdir(os.path.join(data_dir, class_name)):\n",
        "        raise ValueError(f\"Folder {class_name} not found in {data_dir}\")\n",
        "\n",
        "# Set up data generators with increased augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=class_names,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    classes=class_names,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Load pre-trained EfficientNetB3 model\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
        "\n"
      ],
      "metadata": {
        "id": "l0ZiTCLYIgRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(4, activation='softmax')(x)  # 4 classes now\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Define F1 Score metric as a class\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# Compile the model with additional metrics\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', Precision(), Recall(), F1Score()])\n",
        "\n"
      ],
      "metadata": {
        "id": "tzutT2okI7KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Train the model with class weights\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/My Drive/models/skin_lesion_classifier_efficientnetb3.h5')\n",
        "\n",
        "# Print class indices\n",
        "print(\"Class indices:\", train_generator.class_indices)\n"
      ],
      "metadata": {
        "id": "ePKM1OajJALo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to predict image\n",
        "def predict_image(img_path, nv_threshold=0.7):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    if np.argmax(prediction) == class_names.index('NV') and prediction[0][class_names.index('NV')] < nv_threshold:\n",
        "        predicted_class = class_names[np.argsort(prediction[0])[-2]]\n",
        "    else:\n",
        "        predicted_class = class_names[np.argmax(prediction)]\n",
        "\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    return predicted_class, confidence\n",
        "\n"
      ],
      "metadata": {
        "id": "--D4oIxGJJlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finish_dir = '/content/drive/My Drive/finish'\n",
        "# Interactive prediction loop\n",
        "while True:\n",
        "    user_input = input(\"Enter an image number (1-1000) or 'q' to quit: \")\n",
        "\n",
        "    if user_input.lower() == 'q':\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        image_number = int(user_input)\n",
        "\n",
        "        for filename in os.listdir(finish_dir):\n",
        "            if filename.startswith(f\"{image_number}.\") and filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(finish_dir, filename)\n",
        "\n",
        "                predicted_class, confidence = predict_image(img_path)\n",
        "\n",
        "                print(f\"Image: {filename}\")\n",
        "                print(f\"Predicted class: {predicted_class}\")\n",
        "                print(f\"Confidence: {confidence:.2f}\")\n",
        "                print()\n",
        "                break\n",
        "        else:\n",
        "            print(f\"No image found with number {image_number}\")\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter a number or 'q' to quit.\")\n",
        "\n",
        "print(\"Thank you for using the classifier!\")"
      ],
      "metadata": {
        "id": "4ubcOBRAJUwq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}