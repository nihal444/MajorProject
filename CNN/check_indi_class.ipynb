{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/My Drive/images'\n",
        "print(\"Contents of data_dir:\")\n",
        "print(os.listdir(data_dir))\n",
        "IMG_SIZE = (224, 224)  # Change from (300, 300) to (224, 224)  # efficient 300 else 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf7qyLCPrSB1",
        "outputId": "f09f311b-6199-4bc3-ddc1-875398e82b3e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Contents of data_dir:\n",
            "['NV', 'BCC', 'SCC', 'MEL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + keras.backend.epsilon()))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.precision.reset_state()\n",
        "        self.recall.reset_state()\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return base_config"
      ],
      "metadata": {
        "id": "RDuMohkrDLsk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R6lYfM8ArJvP"
      },
      "outputs": [],
      "source": [
        "# Print class indices\n",
        "# print(\"Class indices:\", train_generator.class_indices)\n",
        "# model_saved = tf.keras.models.load_model('/content/drive/My Drive/models/skin_lesion_classifier_resnet50_final.keras')\n",
        "\n",
        "\n",
        "model_saved = tf.keras.models.load_model('/content/drive/My Drive/models/skin_lesion_classifier_resnet50_final.keras',\n",
        "                                         custom_objects={'F1Score': F1Score})\n",
        "# Update class names to include SCC\n",
        "class_names = ['MEL', 'NV', 'BCC', 'SCC']\n",
        "for class_name in class_names:\n",
        "    if not os.path.isdir(os.path.join(data_dir, class_name)):\n",
        "        raise ValueError(f\"Folder {class_name} not found in {data_dir}\")\n",
        "\n",
        "# Function to predict image\n",
        "def predict_image(img_path, nv_threshold=0.7):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = model_saved.predict(img_array)\n",
        "\n",
        "    if np.argmax(prediction) == class_names.index('NV') and prediction[0][class_names.index('NV')] < nv_threshold:\n",
        "        predicted_class = class_names[np.argsort(prediction[0])[-2]]\n",
        "    else:\n",
        "        predicted_class = class_names[np.argmax(prediction)]\n",
        "\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    return predicted_class, confidence\n",
        "\n",
        "finish_dir = '/content/drive/My Drive/finish'\n",
        "# Interactive prediction loop\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finish_dir = '/content/drive/My Drive/finish'\n",
        "count = 0\n",
        "j = 0\n",
        "\n",
        "print(\"Contents of finish_dir:\")\n",
        "print(os.listdir(finish_dir))\n",
        "\n",
        "for i in range(1, 54):\n",
        "    image_found = False\n",
        "    filename = f\"{i}.jpg\"\n",
        "    if filename in os.listdir(finish_dir):\n",
        "        img_path = os.path.join(finish_dir, filename)\n",
        "\n",
        "        try:\n",
        "            predicted_class, confidence = predict_image(img_path)\n",
        "            if predicted_class == 'SCC':\n",
        "                count += 1\n",
        "            print(f\"Image: {filename}\")\n",
        "            print(f\"Predicted class: {predicted_class}\")\n",
        "            print(f\"Confidence: {confidence:.2f}\")\n",
        "            print()\n",
        "            j += 1\n",
        "            image_found = True\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "    if not image_found:\n",
        "        print(f\"No image found with number {i}\")\n",
        "        break\n",
        "\n",
        "if j > 0:\n",
        "    print(f\"accuracy ratio: {count/j:.2f}\")\n",
        "else:\n",
        "    print(\"No images were successfully processed.\")\n",
        "\n",
        "print(f\"Total corredct classifications: {count}\")\n",
        "print(f\"Total images : {j}\")\n",
        "print(\"Thank you for using the classifier!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgzHEcqPrgut",
        "outputId": "79ba0ccd-5ba9-4841-f408-d173dd0464cb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of finish_dir:\n",
            "['BCC', 'MEL', 'SCC', 'NV', '1.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg', '9.jpg', '10.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '20.jpg']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "Image: 1.jpg\n",
            "Predicted class: MEL\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "Image: 2.jpg\n",
            "Predicted class: MEL\n",
            "Confidence: 0.82\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "Image: 3.jpg\n",
            "Predicted class: MEL\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "Image: 4.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 0.80\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
            "Image: 5.jpg\n",
            "Predicted class: MEL\n",
            "Confidence: 0.99\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "Image: 6.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
            "Image: 7.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
            "Image: 8.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "Image: 9.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "Image: 10.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "Image: 11.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step\n",
            "Image: 12.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step\n",
            "Image: 13.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step\n",
            "Image: 14.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step\n",
            "Image: 15.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "Image: 16.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "Image: 17.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "Image: 18.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "Image: 19.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
            "Image: 20.jpg\n",
            "Predicted class: SCC\n",
            "Confidence: 1.00\n",
            "\n",
            "No image found with number 21\n",
            "accuracy ratio: 0.80\n",
            "Total corredct classifications: 16\n",
            "Total images : 20\n",
            "Thank you for using the classifier!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(count , j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC-D1P5xtCFg",
        "outputId": "ba6f7d17-71e5-4b28-c6b5-f3e7a039793d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##    OLD CODE\n",
        "\n",
        "# # -*- coding: utf-8 -*-\n",
        "# \"\"\"check.ipynb\n",
        "\n",
        "# Automatically generated by Colab.\n",
        "\n",
        "# Original file is located at\n",
        "#     https://colab.research.google.com/drive/1-oRzdlFRinkdaxDnwxg4gsSCNqAUw6-C\n",
        "# \"\"\"\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.applications import MobileNetV2\n",
        "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.metrics import Precision, Recall\n",
        "# from tensorflow.keras import backend as K\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# data_dir = '/content/drive/My Drive/images'\n",
        "# print(\"Contents of data_dir:\")\n",
        "# print(os.listdir(data_dir))\n",
        "# IMG_SIZE = (300,300)  # efficient 300 else 224\n",
        "# BATCH_SIZE = 32\n",
        "# EPOCHS = 30\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "\n",
        "# class F1Score(tf.keras.metrics.Metric):\n",
        "#     def __init__(self, name='f1_score', **kwargs):\n",
        "#         super().__init__(name=name, **kwargs)\n",
        "#         self.precision = tf.keras.metrics.Precision()\n",
        "#         self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "#         self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "#         self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "#     def result(self):\n",
        "#         p = self.precision.result()\n",
        "#         r = self.recall.result()\n",
        "#         return 2 * ((p * r) / (p + r + keras.backend.epsilon()))\n",
        "\n",
        "#     def reset_state(self):\n",
        "#         self.precision.reset_state()\n",
        "#         self.recall.reset_state()\n",
        "\n",
        "#     def get_config(self):\n",
        "#         base_config = super().get_config()\n",
        "#         return base_config\n",
        "\n",
        "# # Print class indices\n",
        "# # print(\"Class indices:\", train_generator.class_indices)\n",
        "# model_saved = tf.keras.models.load_model('/content/drive/My Drive/models/skin_lesion_classifier_resnet50_final.keras')\n",
        "# # Update class names to include SCC\n",
        "# class_names = ['MEL', 'NV', 'BCC', 'SCC']\n",
        "# for class_name in class_names:\n",
        "#     if not os.path.isdir(os.path.join(data_dir, class_name)):\n",
        "#         raise ValueError(f\"Folder {class_name} not found in {data_dir}\")\n",
        "\n",
        "# # Function to predict image\n",
        "# def predict_image(img_path, nv_threshold=0.7):\n",
        "#     img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
        "#     img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "#     img_array = np.expand_dims(img_array, axis=0)\n",
        "#     img_array /= 255.0\n",
        "\n",
        "#     prediction = model_saved.predict(img_array)\n",
        "\n",
        "#     if np.argmax(prediction) == class_names.index('NV') and prediction[0][class_names.index('NV')] < nv_threshold:\n",
        "#         predicted_class = class_names[np.argsort(prediction[0])[-2]]\n",
        "#     else:\n",
        "#         predicted_class = class_names[np.argmax(prediction)]\n",
        "\n",
        "#     confidence = np.max(prediction)\n",
        "\n",
        "#     return predicted_class, confidence\n",
        "\n",
        "# finish_dir = '/content/drive/My Drive/finish'\n",
        "# # Interactive prediction loop\n",
        "\n",
        "# count=0\n",
        "# j=0\n",
        "# for i in range(1,54):\n",
        "#     user_input=i\n",
        "#     try:\n",
        "#         image_number = int(user_input)\n",
        "\n",
        "#         for filename in os.listdir(finish_dir):\n",
        "#             if filename.startswith(f\"{image_number}.\") and filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "#                 img_path = os.path.join(finish_dir, filename)\n",
        "\n",
        "#                 predicted_class, confidence = predict_image(img_path)\n",
        "#                 if(predicted_class=='MEL'):\n",
        "#                     count=count+1\n",
        "#                 print(f\"Image: {filename}\")\n",
        "#                 print(f\"Predicted class: {predicted_class}\")\n",
        "#                 print(f\"Confidence: {confidence:.2f}\")\n",
        "#                 print()\n",
        "#                 j+=1\n",
        "#                 break\n",
        "#         else:\n",
        "#             print(f\"No image found with number {image_number}\")\n",
        "#             break\n",
        "\n",
        "#     except ValueError:\n",
        "#         print(\"Invalid input\")\n",
        "\n",
        "# print(count/j)\n",
        "# print(\"Thank you for using the classifier!\")\n",
        "\n",
        "# print(count , j)"
      ],
      "metadata": {
        "id": "lr9D711kGha0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}