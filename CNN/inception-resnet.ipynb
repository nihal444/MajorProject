{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9399616,"sourceType":"datasetVersion","datasetId":5705501}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Set up constants\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 50\n\n# Define the path to the images folder\ndata_dir = '/kaggle/input/images-skinlesion/images'\nclass_names = ['MEL', 'NV', 'BCC', 'SCC']\n\n# Set up data generators with increased augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest',\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    data_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training',\n    classes=class_names,\n    shuffle=True\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    data_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation',\n    classes=class_names,\n    shuffle=False\n)\n\n# Load pre-trained InceptionResNetV2 model\nbase_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-29T14:32:33.993851Z","iopub.execute_input":"2024-09-29T14:32:33.994680Z","iopub.status.idle":"2024-09-29T14:32:40.426825Z","shell.execute_reply.started":"2024-09-29T14:32:33.994641Z","shell.execute_reply":"2024-09-29T14:32:40.425815Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 7174 images belonging to 4 classes.\nFound 1791 images belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Fine-tune the model\nfor layer in base_model.layers:\n    layer.trainable = True\n\n# Add custom layers\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, kernel_regularizer='l2', activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(4, activation='softmax')(x)\n\n# Create the final model\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# Compile the model\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Compute class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\nclass_weight_dict = dict(enumerate(class_weights))\n\n# Define callbacks\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001, verbose=1)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\nmodel_checkpoint = ModelCheckpoint('/kaggle/working/best_model_inceptionresnetv2.keras', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:32:40.428635Z","iopub.execute_input":"2024-09-29T14:32:40.428956Z","iopub.status.idle":"2024-09-29T14:32:40.586648Z","shell.execute_reply.started":"2024-09-29T14:32:40.428922Z","shell.execute_reply":"2024-09-29T14:32:40.585670Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // BATCH_SIZE,\n    epochs=EPOCHS,\n    class_weight=class_weight_dict,\n    callbacks=[reduce_lr, early_stopping, model_checkpoint]\n)\n\nmodel.save('/kaggle/working/skin_lesion_classifier_inceptionresnetv2_final.keras')","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:32:40.587775Z","iopub.execute_input":"2024-09-29T14:32:40.588078Z","iopub.status.idle":"2024-09-29T15:39:53.469456Z","shell.execute_reply.started":"2024-09-29T14:32:40.588047Z","shell.execute_reply":"2024-09-29T15:39:53.468485Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1727620451.946578     113 service.cc:145] XLA service 0x7b5f78002790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1727620451.946641     113 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1727620451.946647     113 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1727620541.916698     113 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_105', 28 bytes spill stores, 28 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_104', 40 bytes spill stores, 40 bytes spill loads\n\nI0000 00:00:1727620542.042508     113 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m220/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 695ms/step - accuracy: 0.6101 - loss: 3.1957","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727620765.703689     111 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion', 72 bytes spill stores, 72 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_566', 16 bytes spill stores, 16 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_117', 40 bytes spill stores, 40 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_118', 28 bytes spill stores, 28 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6113 - loss: 3.1896\nEpoch 1: val_accuracy improved from -inf to 0.81136, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 1s/step - accuracy: 0.6116 - loss: 3.1881 - val_accuracy: 0.8114 - val_loss: 2.5349 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 624ms/step - accuracy: 0.7500 - loss: 2.2998","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2: val_accuracy did not improve from 0.81136\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 2.2998 - val_accuracy: 0.1935 - val_loss: 5.6320 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.7856 - loss: 2.2282\nEpoch 3: val_accuracy improved from 0.81136 to 0.83182, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 704ms/step - accuracy: 0.7856 - loss: 2.2278 - val_accuracy: 0.8318 - val_loss: 1.9596 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 593ms/step - accuracy: 0.7812 - loss: 2.3530\nEpoch 4: val_accuracy did not improve from 0.83182\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.7812 - loss: 2.3530 - val_accuracy: 0.3226 - val_loss: 4.3674 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - accuracy: 0.8015 - loss: 1.7873\nEpoch 5: val_accuracy improved from 0.83182 to 0.84148, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 701ms/step - accuracy: 0.8015 - loss: 1.7869 - val_accuracy: 0.8415 - val_loss: 1.6626 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 552ms/step - accuracy: 0.7812 - loss: 1.5271\nEpoch 6: val_accuracy did not improve from 0.84148\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7812 - loss: 1.5271 - val_accuracy: 0.5161 - val_loss: 2.7844 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.8320 - loss: 1.4625\nEpoch 7: val_accuracy improved from 0.84148 to 0.84602, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 703ms/step - accuracy: 0.8320 - loss: 1.4623 - val_accuracy: 0.8460 - val_loss: 1.3590 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 573ms/step - accuracy: 0.8125 - loss: 1.2323\nEpoch 8: val_accuracy did not improve from 0.84602\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.8125 - loss: 1.2323 - val_accuracy: 0.2581 - val_loss: 3.1475 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.8422 - loss: 1.2148\nEpoch 9: val_accuracy improved from 0.84602 to 0.86080, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 695ms/step - accuracy: 0.8422 - loss: 1.2146 - val_accuracy: 0.8608 - val_loss: 1.1352 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 552ms/step - accuracy: 0.8125 - loss: 1.2277\nEpoch 10: val_accuracy did not improve from 0.86080\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.8125 - loss: 1.2277 - val_accuracy: 0.7097 - val_loss: 2.1394 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.8573 - loss: 0.9814\nEpoch 11: val_accuracy did not improve from 0.86080\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 685ms/step - accuracy: 0.8574 - loss: 0.9813 - val_accuracy: 0.8102 - val_loss: 1.0959 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 485ms/step - accuracy: 0.8125 - loss: 0.9267\nEpoch 12: val_accuracy did not improve from 0.86080\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.8125 - loss: 0.9267 - val_accuracy: 0.3548 - val_loss: 2.9126 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.8747 - loss: 0.8196\nEpoch 13: val_accuracy did not improve from 0.86080\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 686ms/step - accuracy: 0.8747 - loss: 0.8195 - val_accuracy: 0.8102 - val_loss: 1.0583 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 481ms/step - accuracy: 0.8750 - loss: 0.7568\nEpoch 14: val_accuracy did not improve from 0.86080\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.8750 - loss: 0.7568 - val_accuracy: 0.3226 - val_loss: 3.3670 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.8724 - loss: 0.6853\nEpoch 15: val_accuracy improved from 0.86080 to 0.86136, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 706ms/step - accuracy: 0.8725 - loss: 0.6853 - val_accuracy: 0.8614 - val_loss: 0.8867 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 572ms/step - accuracy: 0.9375 - loss: 0.8816\nEpoch 16: val_accuracy did not improve from 0.86136\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.9375 - loss: 0.8816 - val_accuracy: 0.5484 - val_loss: 2.5827 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.8900 - loss: 0.5939\nEpoch 17: val_accuracy did not improve from 0.86136\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 685ms/step - accuracy: 0.8900 - loss: 0.5938 - val_accuracy: 0.7847 - val_loss: 0.8544 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 482ms/step - accuracy: 0.7812 - loss: 0.5947\nEpoch 18: val_accuracy did not improve from 0.86136\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7812 - loss: 0.5947 - val_accuracy: 0.1290 - val_loss: 2.2100 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - accuracy: 0.8879 - loss: 0.5030\nEpoch 19: val_accuracy did not improve from 0.86136\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 687ms/step - accuracy: 0.8879 - loss: 0.5030 - val_accuracy: 0.8273 - val_loss: 0.8483 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 484ms/step - accuracy: 0.9375 - loss: 0.3883\nEpoch 20: val_accuracy did not improve from 0.86136\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.9375 - loss: 0.3883 - val_accuracy: 0.3548 - val_loss: 2.9668 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - accuracy: 0.8956 - loss: 0.4754\nEpoch 21: val_accuracy improved from 0.86136 to 0.87216, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 704ms/step - accuracy: 0.8956 - loss: 0.4752 - val_accuracy: 0.8722 - val_loss: 0.5664 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 581ms/step - accuracy: 0.7188 - loss: 0.3644\nEpoch 22: val_accuracy did not improve from 0.87216\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.7188 - loss: 0.3644 - val_accuracy: 0.5484 - val_loss: 1.8892 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.9088 - loss: 0.3866\nEpoch 23: val_accuracy did not improve from 0.87216\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 680ms/step - accuracy: 0.9088 - loss: 0.3866 - val_accuracy: 0.8182 - val_loss: 0.7589 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 481ms/step - accuracy: 0.8438 - loss: 0.7259\nEpoch 24: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 24: val_accuracy did not improve from 0.87216\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.8438 - loss: 0.7259 - val_accuracy: 0.2581 - val_loss: 3.5144 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - accuracy: 0.9292 - loss: 0.3124\nEpoch 25: val_accuracy improved from 0.87216 to 0.88352, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 693ms/step - accuracy: 0.9292 - loss: 0.3123 - val_accuracy: 0.8835 - val_loss: 0.5394 - learning_rate: 5.0000e-05\nEpoch 26/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 543ms/step - accuracy: 0.9062 - loss: 0.3297\nEpoch 26: val_accuracy did not improve from 0.88352\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.9062 - loss: 0.3297 - val_accuracy: 0.5484 - val_loss: 2.2903 - learning_rate: 5.0000e-05\nEpoch 27/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - accuracy: 0.9311 - loss: 0.2713\nEpoch 27: val_accuracy improved from 0.88352 to 0.89545, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 694ms/step - accuracy: 0.9311 - loss: 0.2713 - val_accuracy: 0.8955 - val_loss: 0.4982 - learning_rate: 5.0000e-05\nEpoch 28/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 543ms/step - accuracy: 1.0000 - loss: 0.1664\nEpoch 28: val_accuracy did not improve from 0.89545\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 1.0000 - loss: 0.1664 - val_accuracy: 0.6129 - val_loss: 1.9370 - learning_rate: 5.0000e-05\nEpoch 29/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.9502 - loss: 0.2269\nEpoch 29: val_accuracy improved from 0.89545 to 0.90511, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 698ms/step - accuracy: 0.9502 - loss: 0.2269 - val_accuracy: 0.9051 - val_loss: 0.4895 - learning_rate: 5.0000e-05\nEpoch 30/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 585ms/step - accuracy: 0.9062 - loss: 0.2510\nEpoch 30: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.9062 - loss: 0.2510 - val_accuracy: 0.4194 - val_loss: 2.8122 - learning_rate: 5.0000e-05\nEpoch 31/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.9546 - loss: 0.2145\nEpoch 31: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 672ms/step - accuracy: 0.9545 - loss: 0.2146 - val_accuracy: 0.8932 - val_loss: 0.4944 - learning_rate: 5.0000e-05\nEpoch 32/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 482ms/step - accuracy: 0.9062 - loss: 0.4160\nEpoch 32: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\nEpoch 32: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.9062 - loss: 0.4160 - val_accuracy: 0.4839 - val_loss: 2.3428 - learning_rate: 5.0000e-05\nEpoch 33/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - accuracy: 0.9633 - loss: 0.1859\nEpoch 33: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 687ms/step - accuracy: 0.9633 - loss: 0.1858 - val_accuracy: 0.8852 - val_loss: 0.5201 - learning_rate: 2.5000e-05\nEpoch 34/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 479ms/step - accuracy: 0.9375 - loss: 0.2819\nEpoch 34: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.9375 - loss: 0.2819 - val_accuracy: 0.4516 - val_loss: 2.8530 - learning_rate: 2.5000e-05\nEpoch 35/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.9625 - loss: 0.1726\nEpoch 35: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 681ms/step - accuracy: 0.9625 - loss: 0.1726 - val_accuracy: 0.9017 - val_loss: 0.4811 - learning_rate: 2.5000e-05\nEpoch 36/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 486ms/step - accuracy: 0.9688 - loss: 0.1467\nEpoch 36: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.9688 - loss: 0.1467 - val_accuracy: 0.4516 - val_loss: 2.3894 - learning_rate: 2.5000e-05\nEpoch 37/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.9704 - loss: 0.1562\nEpoch 37: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 683ms/step - accuracy: 0.9704 - loss: 0.1562 - val_accuracy: 0.8932 - val_loss: 0.4899 - learning_rate: 2.5000e-05\nEpoch 38/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 477ms/step - accuracy: 0.9375 - loss: 0.1935\nEpoch 38: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\nEpoch 38: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.9375 - loss: 0.1935 - val_accuracy: 0.4839 - val_loss: 3.3534 - learning_rate: 2.5000e-05\nEpoch 39/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.9761 - loss: 0.1399\nEpoch 39: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 678ms/step - accuracy: 0.9761 - loss: 0.1399 - val_accuracy: 0.9000 - val_loss: 0.4948 - learning_rate: 1.2500e-05\nEpoch 40/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 479ms/step - accuracy: 0.9688 - loss: 0.1272\nEpoch 40: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.9688 - loss: 0.1272 - val_accuracy: 0.3871 - val_loss: 3.1229 - learning_rate: 1.2500e-05\nEpoch 41/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.9794 - loss: 0.1351\nEpoch 41: ReduceLROnPlateau reducing learning rate to 1e-05.\n\nEpoch 41: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 678ms/step - accuracy: 0.9794 - loss: 0.1351 - val_accuracy: 0.9051 - val_loss: 0.5025 - learning_rate: 1.2500e-05\nEpoch 42/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 490ms/step - accuracy: 0.9688 - loss: 0.1219\nEpoch 42: val_accuracy did not improve from 0.90511\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.9688 - loss: 0.1219 - val_accuracy: 0.3548 - val_loss: 3.3037 - learning_rate: 1.0000e-05\nEpoch 43/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.9763 - loss: 0.1332\nEpoch 43: val_accuracy improved from 0.90511 to 0.90852, saving model to /kaggle/working/best_model_inceptionresnetv2.keras\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 692ms/step - accuracy: 0.9763 - loss: 0.1332 - val_accuracy: 0.9085 - val_loss: 0.4852 - learning_rate: 1.0000e-05\nEpoch 44/50\n\u001b[1m  1/224\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 562ms/step - accuracy: 0.9375 - loss: 0.3745\nEpoch 44: val_accuracy did not improve from 0.90852\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.9375 - loss: 0.3745 - val_accuracy: 0.4516 - val_loss: 3.0978 - learning_rate: 1.0000e-05\nEpoch 45/50\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - accuracy: 0.9827 - loss: 0.1167\nEpoch 45: val_accuracy did not improve from 0.90852\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 682ms/step - accuracy: 0.9827 - loss: 0.1167 - val_accuracy: 0.9034 - val_loss: 0.4928 - learning_rate: 1.0000e-05\nEpoch 45: early stopping\nRestoring model weights from the end of the best epoch: 35.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Evaluate the model\ntest_generator = train_datagen.flow_from_directory(\n    data_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Get predictions\npredictions = model.predict(test_generator)\ny_pred = np.argmax(predictions, axis=1)\ny_true = test_generator.classes\n\n# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('/kaggle/working/confusion_matrix.png')\nplt.close()\n\n# Print classification report\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# Plot training history\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.savefig('/kaggle/working/training_history.png')\nplt.close()\n\n# Save the final model\n\nprint(\"Training completed. Model saved, confusion matrix and training history plots generated.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:39:53.471814Z","iopub.execute_input":"2024-09-29T15:39:53.472301Z","iopub.status.idle":"2024-09-29T15:42:45.166733Z","shell.execute_reply.started":"2024-09-29T15:39:53.472254Z","shell.execute_reply":"2024-09-29T15:42:45.165641Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 8965 images belonging to 4 classes.\n\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 564ms/step\n              precision    recall  f1-score   support\n\n         MEL       0.00      0.00      0.00       514\n          NV       0.01      0.04      0.01      1113\n         BCC       0.04      0.00      0.01      6705\n         SCC       0.97      0.89      0.93       633\n\n    accuracy                           0.07      8965\n   macro avg       0.25      0.23      0.24      8965\nweighted avg       0.10      0.07      0.07      8965\n\nTraining completed. Model saved, confusion matrix and training history plots generated.\n","output_type":"stream"}]}]}