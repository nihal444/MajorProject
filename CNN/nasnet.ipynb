{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9399616,"sourceType":"datasetVersion","datasetId":5705501}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.applications import NASNetLarge\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Constants\nNASNET_SIZE = (331, 331)  # NASNetLarge required size\nBATCH_SIZE = 16\nEPOCHS = 50\nDATA_DIR = '/kaggle/input/images-skinlesion/images'\nCLASS_NAMES = ['MEL', 'NV', 'BCC', 'SCC']\n\ndef preprocess_input(x):\n    # Apply NASNetLarge preprocessing\n    return tf.keras.applications.nasnet.preprocess_input(x)\n\n# Enhanced data augmentation\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=45,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='reflect',\n    brightness_range=[0.7, 1.3],\n    channel_shift_range=0.2,\n    validation_split=0.2\n)\n\n# Create generators with NASNET_SIZE\ntrain_generator = train_datagen.flow_from_directory(\n    DATA_DIR,\n    target_size=NASNET_SIZE,  # Using NASNet required size directly\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training',\n    classes=CLASS_NAMES,\n    shuffle=True\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    DATA_DIR,\n    target_size=NASNET_SIZE,  # Using NASNet required size directly\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation',\n    classes=CLASS_NAMES,\n    shuffle=False\n)\n\n# Calculate class weights\ntotal_samples = 8200\nclass_weights = {\n    0: total_samples/(1000 * len(CLASS_NAMES)),  # MEL\n    1: total_samples/(6000 * len(CLASS_NAMES)),  # NV\n    2: total_samples/(600 * len(CLASS_NAMES)),   # BCC\n    3: total_samples/(600 * len(CLASS_NAMES))    # SCC\n}\n\n# Create model\nbase_model = NASNetLarge(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(*NASNET_SIZE, 3)\n)\n\n# Add custom top layers\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\nx = Dropout(0.5)(x)\nx = BatchNormalization()(x)\nx = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\nx = Dropout(0.3)(x)\noutputs = Dense(len(CLASS_NAMES), activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=outputs)\n\n# Initialize with frozen layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile model\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(\n    optimizer=optimizer,\n    loss='categorical_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.AUC()]\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:47:29.051292Z","iopub.execute_input":"2024-10-04T11:47:29.052022Z","iopub.status.idle":"2024-10-04T11:47:36.692228Z","shell.execute_reply.started":"2024-10-04T11:47:29.051983Z","shell.execute_reply":"2024-10-04T11:47:36.691428Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 7174 images belonging to 4 classes.\nFound 1791 images belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Advanced callbacks\ncallbacks = [\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=3,\n        min_lr=1e-7,\n        verbose=1\n    ),\n    EarlyStopping(\n        monitor='val_loss',\n        patience=10,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        '/kaggle/working/best_model_nasnet.keras',\n        save_best_only=True,\n        monitor='val_accuracy',\n        mode='max',\n        verbose=1\n    )\n]\n\n# Phase 1: Train top layers\nprint(\"Phase 1: Training top layers...\")\nhistory1 = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // BATCH_SIZE,\n    epochs=10,\n    class_weight=class_weights,\n    callbacks=callbacks\n)\n\n# Phase 2: Fine-tune entire model\nprint(\"Phase 2: Fine-tuning entire model...\")\nfor layer in model.layers:\n    layer.trainable = True\n\n# Recompile with lower learning rate for fine-tuning\nmodel.compile(\n    optimizer=Adam(learning_rate=0.00001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.AUC()]\n)\n\n# Full training\nhistory2 = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // BATCH_SIZE,\n    epochs=EPOCHS,\n    class_weight=class_weights,\n    callbacks=callbacks,\n    initial_epoch=10\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T11:47:36.693791Z","iopub.execute_input":"2024-10-04T11:47:36.694103Z","iopub.status.idle":"2024-10-04T16:19:46.343560Z","shell.execute_reply.started":"2024-10-04T11:47:36.694070Z","shell.execute_reply":"2024-10-04T16:19:46.342536Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Phase 1: Training top layers...\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1728042491.488718     112 service.cc:145] XLA service 0x7bc71c003670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1728042491.488771     112 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1728042491.488776     112 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1728042519.903814     112 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636ms/step - accuracy: 0.4897 - auc_1: 0.7432 - loss: 23.3374\nEpoch 1: val_accuracy improved from -inf to 0.61486, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 834ms/step - accuracy: 0.4898 - auc_1: 0.7434 - loss: 23.3349 - val_accuracy: 0.6149 - val_auc_1: 0.8462 - val_loss: 20.2290 - learning_rate: 1.0000e-04\nEpoch 2/10\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:09\u001b[0m 424ms/step - accuracy: 0.5625 - auc_1: 0.7806 - loss: 20.1097","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2: val_accuracy did not improve from 0.61486\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.5625 - auc_1: 0.7806 - loss: 20.1097 - val_accuracy: 0.1333 - val_auc_1: 0.6644 - val_loss: 20.8253 - learning_rate: 1.0000e-04\nEpoch 3/10\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - accuracy: 0.6297 - auc_1: 0.8669 - loss: 19.3512\nEpoch 3: val_accuracy improved from 0.61486 to 0.66104, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 672ms/step - accuracy: 0.6297 - auc_1: 0.8668 - loss: 19.3494 - val_accuracy: 0.6610 - val_auc_1: 0.8864 - val_loss: 16.9543 - learning_rate: 1.0000e-04\nEpoch 4/10\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 414ms/step - accuracy: 0.6875 - auc_1: 0.8672 - loss: 17.5031\nEpoch 4: val_accuracy did not improve from 0.66104\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.6875 - auc_1: 0.8672 - loss: 17.5031 - val_accuracy: 0.1333 - val_auc_1: 0.5548 - val_loss: 17.9893 - learning_rate: 1.0000e-04\nEpoch 5/10\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - accuracy: 0.6412 - auc_1: 0.8786 - loss: 16.2222\nEpoch 5: val_accuracy did not improve from 0.66104\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 673ms/step - accuracy: 0.6412 - auc_1: 0.8786 - loss: 16.2206 - val_accuracy: 0.6582 - val_auc_1: 0.8900 - val_loss: 14.1905 - learning_rate: 1.0000e-04\nEpoch 6/10\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 360ms/step - accuracy: 0.5625 - auc_1: 0.8724 - loss: 13.8031\nEpoch 6: val_accuracy did not improve from 0.66104\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 0.5625 - auc_1: 0.8724 - loss: 13.8031 - val_accuracy: 0.3333 - val_auc_1: 0.6578 - val_loss: 14.8614 - learning_rate: 1.0000e-04\nEpoch 7/10\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step - accuracy: 0.6626 - auc_1: 0.8892 - loss: 13.5470\nEpoch 7: val_accuracy did not improve from 0.66104\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 709ms/step - accuracy: 0.6626 - auc_1: 0.8892 - loss: 13.5457 - val_accuracy: 0.6385 - val_auc_1: 0.8730 - val_loss: 11.9359 - learning_rate: 1.0000e-04\nEpoch 8/10\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 355ms/step - accuracy: 0.6250 - auc_1: 0.8503 - loss: 11.9507\nEpoch 8: val_accuracy did not improve from 0.66104\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.6250 - auc_1: 0.8503 - loss: 11.9507 - val_accuracy: 0.2000 - val_auc_1: 0.6044 - val_loss: 13.0403 - learning_rate: 1.0000e-04\nEpoch 9/10\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.6622 - auc_1: 0.8925 - loss: 11.2191\nEpoch 9: val_accuracy improved from 0.66104 to 0.67399, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 681ms/step - accuracy: 0.6622 - auc_1: 0.8925 - loss: 11.2180 - val_accuracy: 0.6740 - val_auc_1: 0.8924 - val_loss: 9.8610 - learning_rate: 1.0000e-04\nEpoch 10/10\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:17\u001b[0m 442ms/step - accuracy: 0.6875 - auc_1: 0.9271 - loss: 10.0531\nEpoch 10: val_accuracy did not improve from 0.67399\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.6875 - auc_1: 0.9271 - loss: 10.0531 - val_accuracy: 0.0667 - val_auc_1: 0.3867 - val_loss: 11.9002 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 9.\nPhase 2: Fine-tuning entire model...\nEpoch 11/50\n\u001b[1m 91/448\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:25\u001b[0m 1s/step - accuracy: 0.6014 - auc_2: 0.8503 - loss: 10.0968","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1728044879.390784     115 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_3', 4 bytes spill stores, 4 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6028 - auc_2: 0.8536 - loss: 9.9573\nEpoch 11: val_accuracy improved from 0.67399 to 0.77421, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1310s\u001b[0m 2s/step - accuracy: 0.6028 - auc_2: 0.8536 - loss: 9.9571 - val_accuracy: 0.7742 - val_auc_2: 0.9099 - val_loss: 10.3244 - learning_rate: 1.0000e-05\nEpoch 12/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:48\u001b[0m 1s/step - accuracy: 0.6250 - auc_2: 0.8548 - loss: 9.4499\nEpoch 12: val_accuracy did not improve from 0.77421\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.6250 - auc_2: 0.8548 - loss: 9.4499 - val_accuracy: 0.0667 - val_auc_2: 0.2015 - val_loss: 20.4304 - learning_rate: 1.0000e-05\nEpoch 13/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6471 - auc_2: 0.8825 - loss: 9.5299\nEpoch 13: val_accuracy improved from 0.77421 to 0.77872, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 2s/step - accuracy: 0.6471 - auc_2: 0.8825 - loss: 9.5297 - val_accuracy: 0.7787 - val_auc_2: 0.9126 - val_loss: 9.9884 - learning_rate: 1.0000e-05\nEpoch 14/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:36\u001b[0m 1s/step - accuracy: 0.5625 - auc_2: 0.8828 - loss: 9.1455\nEpoch 14: val_accuracy did not improve from 0.77872\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 929us/step - accuracy: 0.5625 - auc_2: 0.8828 - loss: 9.1455 - val_accuracy: 0.0000e+00 - val_auc_2: 0.0963 - val_loss: 19.5372 - learning_rate: 1.0000e-05\nEpoch 15/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6791 - auc_2: 0.9057 - loss: 9.2280\nEpoch 15: val_accuracy improved from 0.77872 to 0.78829, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 2s/step - accuracy: 0.6791 - auc_2: 0.9057 - loss: 9.2279 - val_accuracy: 0.7883 - val_auc_2: 0.9238 - val_loss: 9.6377 - learning_rate: 1.0000e-05\nEpoch 16/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:54\u001b[0m 1s/step - accuracy: 0.7500 - auc_2: 0.9564 - loss: 8.7955\nEpoch 16: val_accuracy did not improve from 0.78829\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 947us/step - accuracy: 0.7500 - auc_2: 0.9564 - loss: 8.7955 - val_accuracy: 0.0000e+00 - val_auc_2: 0.0467 - val_loss: 17.1029 - learning_rate: 1.0000e-05\nEpoch 17/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7094 - auc_2: 0.9193 - loss: 8.9630\nEpoch 17: val_accuracy improved from 0.78829 to 0.80180, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 2s/step - accuracy: 0.7094 - auc_2: 0.9193 - loss: 8.9629 - val_accuracy: 0.8018 - val_auc_2: 0.9377 - val_loss: 9.1531 - learning_rate: 1.0000e-05\nEpoch 18/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:39\u001b[0m 1s/step - accuracy: 0.5625 - auc_2: 0.8288 - loss: 8.9664\nEpoch 18: val_accuracy did not improve from 0.80180\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 970us/step - accuracy: 0.5625 - auc_2: 0.8288 - loss: 8.9664 - val_accuracy: 0.0667 - val_auc_2: 0.0889 - val_loss: 15.6718 - learning_rate: 1.0000e-05\nEpoch 19/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7239 - auc_2: 0.9306 - loss: 8.7369\nEpoch 19: val_accuracy improved from 0.80180 to 0.80800, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 2s/step - accuracy: 0.7239 - auc_2: 0.9306 - loss: 8.7368 - val_accuracy: 0.8080 - val_auc_2: 0.9459 - val_loss: 8.8141 - learning_rate: 1.0000e-05\nEpoch 20/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:45\u001b[0m 1s/step - accuracy: 0.8750 - auc_2: 0.9896 - loss: 8.2354\nEpoch 20: val_accuracy did not improve from 0.80800\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 957us/step - accuracy: 0.8750 - auc_2: 0.9896 - loss: 8.2354 - val_accuracy: 0.0000e+00 - val_auc_2: 0.1985 - val_loss: 13.2082 - learning_rate: 1.0000e-05\nEpoch 21/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7430 - auc_2: 0.9396 - loss: 8.4672\nEpoch 21: val_accuracy improved from 0.80800 to 0.82489, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 2s/step - accuracy: 0.7430 - auc_2: 0.9396 - loss: 8.4671 - val_accuracy: 0.8249 - val_auc_2: 0.9526 - val_loss: 8.5172 - learning_rate: 1.0000e-05\nEpoch 22/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:35\u001b[0m 1s/step - accuracy: 0.6875 - auc_2: 0.9173 - loss: 8.1239\nEpoch 22: val_accuracy did not improve from 0.82489\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 956us/step - accuracy: 0.6875 - auc_2: 0.9173 - loss: 8.1239 - val_accuracy: 0.0000e+00 - val_auc_2: 0.2067 - val_loss: 12.4427 - learning_rate: 1.0000e-05\nEpoch 23/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7522 - auc_2: 0.9447 - loss: 8.2390\nEpoch 23: val_accuracy did not improve from 0.82489\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 2s/step - accuracy: 0.7522 - auc_2: 0.9447 - loss: 8.2389 - val_accuracy: 0.8221 - val_auc_2: 0.9569 - val_loss: 8.2598 - learning_rate: 1.0000e-05\nEpoch 24/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:26\u001b[0m 1s/step - accuracy: 0.6875 - auc_2: 0.9355 - loss: 8.1074\nEpoch 24: val_accuracy did not improve from 0.82489\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955us/step - accuracy: 0.6875 - auc_2: 0.9355 - loss: 8.1074 - val_accuracy: 0.0000e+00 - val_auc_2: 0.1852 - val_loss: 12.0546 - learning_rate: 1.0000e-05\nEpoch 25/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7755 - auc_2: 0.9515 - loss: 8.0068\nEpoch 25: val_accuracy improved from 0.82489 to 0.84291, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 2s/step - accuracy: 0.7755 - auc_2: 0.9515 - loss: 8.0067 - val_accuracy: 0.8429 - val_auc_2: 0.9617 - val_loss: 7.9719 - learning_rate: 1.0000e-05\nEpoch 26/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:50\u001b[0m 1s/step - accuracy: 0.8750 - auc_2: 0.9922 - loss: 7.6838\nEpoch 26: val_accuracy did not improve from 0.84291\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 935us/step - accuracy: 0.8750 - auc_2: 0.9922 - loss: 7.6838 - val_accuracy: 0.2000 - val_auc_2: 0.4474 - val_loss: 10.9770 - learning_rate: 1.0000e-05\nEpoch 27/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7855 - auc_2: 0.9555 - loss: 7.7576\nEpoch 27: val_accuracy improved from 0.84291 to 0.84516, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 2s/step - accuracy: 0.7855 - auc_2: 0.9555 - loss: 7.7575 - val_accuracy: 0.8452 - val_auc_2: 0.9617 - val_loss: 7.7360 - learning_rate: 1.0000e-05\nEpoch 28/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:49\u001b[0m 1s/step - accuracy: 0.5000 - auc_2: 0.8223 - loss: 7.6280\nEpoch 28: val_accuracy did not improve from 0.84516\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step - accuracy: 0.5000 - auc_2: 0.8223 - loss: 7.6280 - val_accuracy: 0.0000e+00 - val_auc_2: 0.3422 - val_loss: 10.7440 - learning_rate: 1.0000e-05\nEpoch 29/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8133 - auc_2: 0.9644 - loss: 7.4856\nEpoch 29: val_accuracy did not improve from 0.84516\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 2s/step - accuracy: 0.8133 - auc_2: 0.9644 - loss: 7.4855 - val_accuracy: 0.8367 - val_auc_2: 0.9636 - val_loss: 7.5002 - learning_rate: 1.0000e-05\nEpoch 30/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:27\u001b[0m 1s/step - accuracy: 0.8750 - auc_2: 0.9948 - loss: 7.1524\nEpoch 30: val_accuracy did not improve from 0.84516\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 947us/step - accuracy: 0.8750 - auc_2: 0.9948 - loss: 7.1524 - val_accuracy: 0.2667 - val_auc_2: 0.4370 - val_loss: 10.6495 - learning_rate: 1.0000e-05\nEpoch 31/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8075 - auc_2: 0.9656 - loss: 7.2402\nEpoch 31: val_accuracy improved from 0.84516 to 0.84854, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 2s/step - accuracy: 0.8075 - auc_2: 0.9656 - loss: 7.2401 - val_accuracy: 0.8485 - val_auc_2: 0.9680 - val_loss: 7.2219 - learning_rate: 1.0000e-05\nEpoch 32/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:38\u001b[0m 1s/step - accuracy: 0.9375 - auc_2: 0.9922 - loss: 7.0032\nEpoch 32: val_accuracy did not improve from 0.84854\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 936us/step - accuracy: 0.9375 - auc_2: 0.9922 - loss: 7.0032 - val_accuracy: 0.1333 - val_auc_2: 0.4378 - val_loss: 10.0322 - learning_rate: 1.0000e-05\nEpoch 33/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8407 - auc_2: 0.9715 - loss: 6.9633\nEpoch 33: val_accuracy improved from 0.84854 to 0.85248, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m702s\u001b[0m 2s/step - accuracy: 0.8407 - auc_2: 0.9715 - loss: 6.9632 - val_accuracy: 0.8525 - val_auc_2: 0.9700 - val_loss: 6.9701 - learning_rate: 1.0000e-05\nEpoch 34/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:52\u001b[0m 1s/step - accuracy: 0.9375 - auc_2: 0.9857 - loss: 7.1416\nEpoch 34: val_accuracy did not improve from 0.85248\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963us/step - accuracy: 0.9375 - auc_2: 0.9857 - loss: 7.1416 - val_accuracy: 0.4667 - val_auc_2: 0.5815 - val_loss: 8.9353 - learning_rate: 1.0000e-05\nEpoch 35/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8375 - auc_2: 0.9702 - loss: 6.7579\nEpoch 35: val_accuracy improved from 0.85248 to 0.85867, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 2s/step - accuracy: 0.8375 - auc_2: 0.9702 - loss: 6.7577 - val_accuracy: 0.8587 - val_auc_2: 0.9733 - val_loss: 6.6997 - learning_rate: 1.0000e-05\nEpoch 36/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:47\u001b[0m 1s/step - accuracy: 0.8125 - auc_2: 0.9642 - loss: 6.5599\nEpoch 36: val_accuracy did not improve from 0.85867\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step - accuracy: 0.8125 - auc_2: 0.9642 - loss: 6.5599 - val_accuracy: 0.4667 - val_auc_2: 0.6852 - val_loss: 8.0933 - learning_rate: 1.0000e-05\nEpoch 37/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8569 - auc_2: 0.9759 - loss: 6.4761\nEpoch 37: val_accuracy did not improve from 0.85867\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 2s/step - accuracy: 0.8569 - auc_2: 0.9759 - loss: 6.4760 - val_accuracy: 0.8508 - val_auc_2: 0.9678 - val_loss: 6.5099 - learning_rate: 1.0000e-05\nEpoch 38/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:19\u001b[0m 1s/step - accuracy: 0.9375 - auc_2: 0.9922 - loss: 6.2897\nEpoch 38: val_accuracy did not improve from 0.85867\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955us/step - accuracy: 0.9375 - auc_2: 0.9922 - loss: 6.2897 - val_accuracy: 0.4000 - val_auc_2: 0.6096 - val_loss: 8.7744 - learning_rate: 1.0000e-05\nEpoch 39/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8536 - auc_2: 0.9746 - loss: 6.2222\nEpoch 39: val_accuracy did not improve from 0.85867\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 2s/step - accuracy: 0.8537 - auc_2: 0.9746 - loss: 6.2220 - val_accuracy: 0.8564 - val_auc_2: 0.9758 - val_loss: 6.1994 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:21\u001b[0m 1s/step - accuracy: 0.7500 - auc_2: 0.9336 - loss: 6.0595\nEpoch 40: val_accuracy did not improve from 0.85867\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966us/step - accuracy: 0.7500 - auc_2: 0.9336 - loss: 6.0595 - val_accuracy: 0.3333 - val_auc_2: 0.6319 - val_loss: 8.5103 - learning_rate: 1.0000e-05\nEpoch 41/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8781 - auc_2: 0.9810 - loss: 5.9680\nEpoch 41: val_accuracy improved from 0.85867 to 0.86712, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 2s/step - accuracy: 0.8781 - auc_2: 0.9810 - loss: 5.9679 - val_accuracy: 0.8671 - val_auc_2: 0.9702 - val_loss: 6.0107 - learning_rate: 1.0000e-05\nEpoch 42/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:50\u001b[0m 1s/step - accuracy: 0.7500 - auc_2: 0.9661 - loss: 5.9673\nEpoch 42: val_accuracy did not improve from 0.86712\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963us/step - accuracy: 0.7500 - auc_2: 0.9661 - loss: 5.9673 - val_accuracy: 0.3333 - val_auc_2: 0.6356 - val_loss: 8.2686 - learning_rate: 1.0000e-05\nEpoch 43/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8825 - auc_2: 0.9826 - loss: 5.7013\nEpoch 43: val_accuracy did not improve from 0.86712\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 2s/step - accuracy: 0.8825 - auc_2: 0.9826 - loss: 5.7012 - val_accuracy: 0.8666 - val_auc_2: 0.9725 - val_loss: 5.7584 - learning_rate: 1.0000e-05\nEpoch 44/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:27\u001b[0m 1s/step - accuracy: 0.8125 - auc_2: 0.9870 - loss: 5.4971\nEpoch 44: val_accuracy did not improve from 0.86712\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 965us/step - accuracy: 0.8125 - auc_2: 0.9870 - loss: 5.4971 - val_accuracy: 0.3333 - val_auc_2: 0.6133 - val_loss: 8.2578 - learning_rate: 1.0000e-05\nEpoch 45/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8969 - auc_2: 0.9850 - loss: 5.4328\nEpoch 45: val_accuracy improved from 0.86712 to 0.86824, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 2s/step - accuracy: 0.8969 - auc_2: 0.9850 - loss: 5.4327 - val_accuracy: 0.8682 - val_auc_2: 0.9715 - val_loss: 5.5335 - learning_rate: 1.0000e-05\nEpoch 46/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:48\u001b[0m 1s/step - accuracy: 0.9375 - auc_2: 0.9987 - loss: 5.1733\nEpoch 46: val_accuracy did not improve from 0.86824\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955us/step - accuracy: 0.9375 - auc_2: 0.9987 - loss: 5.1733 - val_accuracy: 0.3333 - val_auc_2: 0.6259 - val_loss: 8.4068 - learning_rate: 1.0000e-05\nEpoch 47/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8919 - auc_2: 0.9848 - loss: 5.2293\nEpoch 47: val_accuracy did not improve from 0.86824\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m692s\u001b[0m 2s/step - accuracy: 0.8919 - auc_2: 0.9848 - loss: 5.2291 - val_accuracy: 0.8649 - val_auc_2: 0.9709 - val_loss: 5.3088 - learning_rate: 1.0000e-05\nEpoch 48/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:33\u001b[0m 1s/step - accuracy: 0.9375 - auc_2: 0.9857 - loss: 5.0477\nEpoch 48: val_accuracy did not improve from 0.86824\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 973us/step - accuracy: 0.9375 - auc_2: 0.9857 - loss: 5.0477 - val_accuracy: 0.3333 - val_auc_2: 0.4970 - val_loss: 8.7105 - learning_rate: 1.0000e-05\nEpoch 49/50\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8975 - auc_2: 0.9863 - loss: 4.9725\nEpoch 49: val_accuracy improved from 0.86824 to 0.87838, saving model to /kaggle/working/best_model_nasnet.keras\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 2s/step - accuracy: 0.8975 - auc_2: 0.9863 - loss: 4.9724 - val_accuracy: 0.8784 - val_auc_2: 0.9769 - val_loss: 5.0136 - learning_rate: 1.0000e-05\nEpoch 50/50\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:49\u001b[0m 1s/step - accuracy: 0.9375 - auc_2: 0.9844 - loss: 4.7595\nEpoch 50: val_accuracy did not improve from 0.87838\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955us/step - accuracy: 0.9375 - auc_2: 0.9844 - loss: 4.7595 - val_accuracy: 0.2000 - val_auc_2: 0.5881 - val_loss: 8.2580 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 49.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation and visualization functions\ndef plot_training_history(history1, history2):\n    plt.figure(figsize=(15, 5))\n    \n    acc = history1.history['accuracy'] + history2.history['accuracy']\n    val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']\n    loss = history1.history['loss'] + history2.history['loss']\n    val_loss = history1.history['val_loss'] + history2.history['val_loss']\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/training_history_nasnet.png')\n    plt.close()\n\n# Generate predictions\npredictions = model.predict(validation_generator)\ny_pred = np.argmax(predictions, axis=1)\ny_true = validation_generator.classes\n\n# Plot confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=CLASS_NAMES, \n            yticklabels=CLASS_NAMES)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('/kaggle/working/confusion_matrix_nasnet.png')\nplt.close()\n\n# Print classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n\n# Save final model\nmodel.save('/kaggle/working/skin_lesion_classifier_nasnet_final.keras')\n\n# Plot training history\nplot_training_history(history1, history2)\n\nprint(\"Training completed. Model and visualization artifacts saved.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T16:19:46.345536Z","iopub.execute_input":"2024-10-04T16:19:46.345878Z","iopub.status.idle":"2024-10-04T16:21:22.517436Z","shell.execute_reply.started":"2024-10-04T16:19:46.345843Z","shell.execute_reply":"2024-10-04T16:21:22.516422Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 651ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n         MEL       0.67      0.66      0.67       222\n          NV       0.93      0.95      0.94      1341\n         BCC       0.59      0.89      0.71       102\n         SCC       0.86      0.35      0.50       126\n\n    accuracy                           0.87      1791\n   macro avg       0.76      0.71      0.70      1791\nweighted avg       0.88      0.87      0.86      1791\n\nTraining completed. Model and visualization artifacts saved.\n","output_type":"stream"}]}]}